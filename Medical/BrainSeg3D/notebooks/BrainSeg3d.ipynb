{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ORy6pqUdmU-x",
        "outputId": "15d40b19-0404-4a38-d271-d8fc5b30bca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "NumPy version: 2.0.2\n",
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Installing PyTorch (this may take a minute)...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
            "Installing MONAI (this may take a few minutes)...\n",
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.24 (from monai)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, monai\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed monai-1.4.0 numpy-1.26.4\n",
            "\n",
            "--------------------------------------------\n",
            "IMPORTANT: Please restart the runtime now by clicking Runtime > Restart runtime\n",
            "Then run the next cells after restart\n",
            "--------------------------------------------\n",
            "NumPy version: 2.0.2\n",
            "PyTorch version: 2.6.0+cu118\n",
            "CUDA available: True\n",
            "CUDA version: 11.8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dea3eb5268e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Import MONAI components - with error handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecollate_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     from monai.transforms import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# load directory modules only, skip loading individual files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mload_submodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcludes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# load all modules, this will trigger all export decorations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/utils/module.py\u001b[0m in \u001b[0;36mload_submodules\u001b[0;34m(basemod, load_all, exclude_pattern)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_pkg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mload_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mmod_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmod_spec\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmod_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossValidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecathlonDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMedNISTDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTciaDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmmars\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_DESC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemoteMMARKeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mmar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_from_mmar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSUPPORTED_HASH_TYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_definitions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPathLike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m from monai.data import (\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mCacheDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mPydicomReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsv_saver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSVSaver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m from .dataset import (\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mArrayDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mCacheDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSUPPORTED_PICKLE_MOD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_tables_to_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_hashing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomizable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomizableTrait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_contiguous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_ops_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAX_SEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_up_option\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madaptors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionSignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_alias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneOf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomOrder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSomeOf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m from .croppad.array import (\n\u001b[1;32m     17\u001b[0m     \u001b[0mBorderPad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/transforms/compose.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNdarrayOrTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvertibleTransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# For backwards compatibility (so this still works: from monai.transforms.compose import MapTransform)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/transforms/inverse.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_affine_nd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvertibleTrait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from monai.utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mLazyAttr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRandomizable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThreadUnsafe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomizableTrait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m     \u001b[0mAn\u001b[0m \u001b[0minterface\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mstate\u001b[0m \u001b[0mlocally\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrently\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mRandomizable\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRandomizable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "# BrainSeg3D: 3D U-Net Implementation for Brain Tumor Segmentation\n",
        "# =================================================================\n",
        "\n",
        "\"\"\"\n",
        "This project implements a 3D U-Net architecture for volumetric brain segmentation,\n",
        "with a focus on tumor segmentation using multi-modal MRI data.\n",
        "\n",
        "Key features:\n",
        "- 3D convolutions for volumetric data processing\n",
        "- Skip connections between encoder and decoder paths\n",
        "- Multi-class segmentation for brain tumor regions\n",
        "- Visualization tools for 3D medical imaging\n",
        "\"\"\"\n",
        "\n",
        "# Print existing Python/NumPy versions first\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "!python -c \"import numpy; print(f'NumPy version: {numpy.__version__}')\"\n",
        "\n",
        "# Clean pip cache to avoid potential conflicts\n",
        "!pip cache purge\n",
        "!pip --version\n",
        "\n",
        "# Install basic dependencies first (should be quick and reliable)\n",
        "!pip install nibabel matplotlib tqdm --quiet\n",
        "\n",
        "# Install PyTorch using the recommended Colab approach\n",
        "# This uses pre-compiled binaries compatible with Colab's CUDA\n",
        "print(\"Installing PyTorch (this may take a minute)...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Now install MONAI without version pinning to get latest stable\n",
        "print(\"Installing MONAI (this may take a few minutes)...\")\n",
        "!pip install monai\n",
        "\n",
        "# IMPORTANT: Restart runtime after installations\n",
        "print(\"\\n--------------------------------------------\")\n",
        "print(\"IMPORTANT: Please restart the runtime now by clicking Runtime > Restart runtime\")\n",
        "print(\"Then run the next cells after restart\")\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "# After restarting runtime, run this part:\n",
        "\n",
        "# Import base libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Print versions for debugging\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n",
        "\n",
        "# Import MONAI components - with error handling\n",
        "try:\n",
        "    import monai\n",
        "    from monai.data import Dataset, decollate_batch\n",
        "    from monai.transforms import (\n",
        "        Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd,\n",
        "        RandCropByPosNegLabeld, Orientationd, ToTensord, RandFlipd,\n",
        "        NormalizeIntensityd\n",
        "    )\n",
        "    from monai.networks.nets import UNet\n",
        "    from monai.networks.layers import Norm\n",
        "    from monai.losses import DiceLoss\n",
        "    from monai.inferers import sliding_window_inference\n",
        "    from monai.visualize import plot_2d_or_3d_image\n",
        "    from monai.utils import set_determinism\n",
        "    from monai.apps import download_and_extract\n",
        "\n",
        "    print(f\"MONAI version: {monai.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing MONAI: {e}\")\n",
        "    print(\"Please restart the runtime and try again.\")\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_determinism(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Setup and Download\n",
        "# ==========================\n",
        "\n",
        "# Create a directory for data\n",
        "os.makedirs(\"./brain_data\", exist_ok=True)\n",
        "\n",
        "# Use MONAI's built-in functionality for downloading datasets\n",
        "try:\n",
        "    print(\"Attempting to download BraTS sample data with MONAI...\")\n",
        "\n",
        "    # Import necessary MONAI components for downloading datasets\n",
        "    from monai.apps.utils import download_and_extract\n",
        "\n",
        "    # Download a small sample of BraTS data (10 cases)\n",
        "    resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MSD_Task01_BrainTumour_sub.tar.gz\"\n",
        "    tarfile_name = os.path.join(\"./brain_data\", \"MSD_Task01_BrainTumour_sub.tar.gz\")\n",
        "\n",
        "    # Download and extract\n",
        "    download_and_extract(\n",
        "        url=resource,\n",
        "        filepath=tarfile_name,\n",
        "        output_dir=\"./brain_data\",\n",
        "        hash_type=\"md5\",\n",
        "    )\n",
        "\n",
        "    data_dir = os.path.join(\"./brain_data\", \"Task01_BrainTumour\")\n",
        "\n",
        "    # Verify data exists\n",
        "    if not os.path.exists(data_dir):\n",
        "        raise FileNotFoundError(f\"Data directory {data_dir} not found after extraction\")\n",
        "\n",
        "    image_dir = os.path.join(data_dir, \"imagesTr\")\n",
        "    label_dir = os.path.join(data_dir, \"labelsTr\")\n",
        "\n",
        "    if not os.path.exists(image_dir) or not os.path.exists(label_dir):\n",
        "        raise FileNotFoundError(f\"Image or label directory not found in {data_dir}\")\n",
        "\n",
        "    # Get data files\n",
        "    training_images = sorted(os.listdir(image_dir))\n",
        "    training_labels = sorted(os.listdir(label_dir))\n",
        "\n",
        "    print(f\"Dataset download successful!\")\n",
        "    print(f\"Dataset path: {data_dir}\")\n",
        "    print(f\"Number of images: {len(training_images)}\")\n",
        "    print(f\"Number of labels: {len(training_labels)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading dataset: {e}\")\n",
        "    print(\"\\nFalling back to creating synthetic data for demonstration...\")\n",
        "\n",
        "    # Create synthetic data as a fallback\n",
        "    import nibabel as nib\n",
        "    import numpy as np\n",
        "\n",
        "    data_dir = \"./brain_data/synthetic\"\n",
        "    image_dir = os.path.join(data_dir, \"imagesTr\")\n",
        "    label_dir = os.path.join(data_dir, \"labelsTr\")\n",
        "\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "    # Create a few synthetic samples\n",
        "    num_samples = 4\n",
        "    for i in range(num_samples):\n",
        "        # Create synthetic multi-modal MRI (4 channels: T1, T1ce, T2, FLAIR)\n",
        "        # Use a smaller size (64x64x64) to save memory\n",
        "        image_data = np.zeros((4, 64, 64, 64), dtype=np.float32)\n",
        "\n",
        "        # Create different patterns for each modality\n",
        "        for c in range(4):\n",
        "            # Create a basic spherical structure\n",
        "            x, y, z = np.ogrid[:64, :64, :64]\n",
        "            center = 32\n",
        "            r = 20\n",
        "            sphere = (x - center)**2 + (y - center)**2 + (z - center)**2 <= r**2\n",
        "\n",
        "            # Add some random noise\n",
        "            noise = np.random.rand(64, 64, 64) * 0.2\n",
        "\n",
        "            # Combine sphere and noise with different intensities per channel\n",
        "            image_data[c] = sphere.astype(float) * (0.5 + c*0.1) + noise\n",
        "\n",
        "        # Create a synthetic segmentation mask\n",
        "        label_data = np.zeros((64, 64, 64), dtype=np.uint8)\n",
        "\n",
        "        # Create tumor core (label 1)\n",
        "        r_core = 10\n",
        "        core_sphere = (x - center)**2 + (y - center)**2 + (z - center)**2 <= r_core**2\n",
        "        label_data[core_sphere] = 1\n",
        "\n",
        "        # Create enhancing tumor (label 2) as a shell around the core\n",
        "        r_enhancing = 15\n",
        "        enhancing_sphere = (x - center)**2 + (y - center)**2 + (z - center)**2 <= r_enhancing**2\n",
        "        label_data[enhancing_sphere & ~core_sphere] = 2\n",
        "\n",
        "        # Save as NIfTI files\n",
        "        affine = np.eye(4)  # Identity affine matrix\n",
        "\n",
        "        # Save image\n",
        "        image_file = os.path.join(image_dir, f\"brain_{i:03d}.nii.gz\")\n",
        "        nib.save(nib.Nifti1Image(image_data, affine), image_file)\n",
        "\n",
        "        # Save label\n",
        "        label_file = os.path.join(label_dir, f\"brain_{i:03d}.nii.gz\")\n",
        "        nib.save(nib.Nifti1Image(label_data, affine), label_file)\n",
        "\n",
        "    # Get data files\n",
        "    training_images = sorted(os.listdir(image_dir))\n",
        "    training_labels = sorted(os.listdir(label_dir))\n",
        "\n",
        "    print(f\"Created synthetic dataset with {num_samples} samples\")\n",
        "    print(f\"Dataset path: {data_dir}\")\n",
        "    print(f\"Number of images: {len(training_images)}\")\n",
        "    print(f\"Number of labels: {len(training_labels)}\")\n",
        "\n",
        "# Display dataset information\n",
        "print(\"\\nData Description:\")\n",
        "print(\"- Multi-modal MRI scans (4 channels: T1, T1ce, T2, FLAIR)\")\n",
        "print(\"- Segmentation labels: Background (0), Tumor core (1), Enhancing tumor (2)\")\n",
        "print(\"- 3D volumetric data\")\n",
        "\n",
        "# List a few example files\n",
        "print(\"\\nExample files:\")\n",
        "for i in range(min(3, len(training_images))):\n",
        "    print(f\"Image {i}: {training_images[i]}\")\n",
        "    print(f\"Label {i}: {training_labels[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "3AqFWZvXmnjl",
        "outputId": "2797d75c-e474-4684-ceb6-2647bd1dd93a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download BraTS sample data with MONAI...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MSD_Task01_BrainTumour_sub.tar.gz: 0.00B [00:00, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-06 14:59:19,098 - ERROR - Download failed from https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MSD_Task01_BrainTumour_sub.tar.gz to /tmp/tmpamk0hv2d/MSD_Task01_BrainTumour_sub.tar.gz.\n",
            "Error downloading dataset: HTTP Error 404: Not Found\n",
            "\n",
            "Falling back to creating synthetic data for demonstration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f612470436c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Download and extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     download_and_extract(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(url, filepath, output_dir, hash_val, hash_type, file_type, has_base, progress)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhash_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhash_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, filepath, hash_val, hash_type, progress, **gdown_kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0m_download_with_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtmp_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/utils.py\u001b[0m in \u001b[0;36m_download_with_progress\u001b[0;34m(url, filepath, progress)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Download failed from {url} to {filepath}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/utils.py\u001b[0m in \u001b[0;36m_download_with_progress\u001b[0;34m(url, filepath, progress)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTqdmUpTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_divisor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_basename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f612470436c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Add some random noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# Combine sphere and noise with different intensities per channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Exploration and Visualization\n",
        "# ==================================\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to safely load a NIfTI file with error handling\n",
        "def load_nifti_file(file_path):\n",
        "    try:\n",
        "        nii_img = nib.load(file_path)\n",
        "        return nii_img\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get the paths to the first image and label\n",
        "try:\n",
        "    image_files = sorted(os.listdir(os.path.join(data_dir, \"imagesTr\")))\n",
        "    label_files = sorted(os.listdir(os.path.join(data_dir, \"labelsTr\")))\n",
        "\n",
        "    first_image_path = os.path.join(data_dir, \"imagesTr\", image_files[0])\n",
        "    first_label_path = os.path.join(data_dir, \"labelsTr\", label_files[0])\n",
        "\n",
        "    print(f\"Loading image: {first_image_path}\")\n",
        "    print(f\"Loading label: {first_label_path}\")\n",
        "\n",
        "    # Load the first image and label using NiBabel\n",
        "    image_nii = load_nifti_file(first_image_path)\n",
        "    label_nii = load_nifti_file(first_label_path)\n",
        "\n",
        "    if image_nii is None or label_nii is None:\n",
        "        raise ValueError(\"Failed to load image or label file\")\n",
        "\n",
        "    # Get data from NIfTI objects\n",
        "    image_data = image_nii.get_fdata()\n",
        "    label_data = label_nii.get_fdata()\n",
        "\n",
        "    # Print shape information\n",
        "    print(f\"Image shape: {image_data.shape}\")\n",
        "    print(f\"Label shape: {label_data.shape}\")\n",
        "\n",
        "    # For 3D volumes, the channel dimension might be last, check and transpose if needed\n",
        "    if len(image_data.shape) == 4 and image_data.shape[-1] == 4:\n",
        "        # If channels are last (e.g., H x W x D x C), transpose to C x H x W x D\n",
        "        image_data = np.transpose(image_data, (3, 0, 1, 2))\n",
        "    elif len(image_data.shape) == 3:\n",
        "        # If it's a single channel image, add channel dimension\n",
        "        image_data = np.expand_dims(image_data, axis=0)\n",
        "\n",
        "    print(f\"Image shape after preprocessing: {image_data.shape}\")\n",
        "    print(f\"Image data type: {image_data.dtype}\")\n",
        "    print(f\"Image value range: [{np.min(image_data)}, {np.max(image_data)}]\")\n",
        "    print(f\"Label data type: {label_data.dtype}\")\n",
        "    print(f\"Unique labels: {np.unique(label_data)}\")\n",
        "\n",
        "    # Visualize a central slice from each modality\n",
        "    central_slice_idx = image_data.shape[2] // 2\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    modalities = [\"T1\", \"T1ce\", \"T2\", \"FLAIR\"]\n",
        "    for i in range(min(4, image_data.shape[0])):\n",
        "        plt.subplot(1, 4, i+1)\n",
        "        plt.imshow(image_data[i, :, :, central_slice_idx], cmap=\"gray\")\n",
        "        plt.title(f\"Modality: {modalities[i] if i < len(modalities) else f'Channel {i}'}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during visualization: {e}\")\n",
        "    print(\"\\nTrying alternative approach...\")\n",
        "\n",
        "    # Fallback approach using synthetic data\n",
        "    try:\n",
        "        # Generate a simple 3D volume if we can't load from files\n",
        "        print(\"Creating sample data for visualization...\")\n",
        "\n",
        "        # Create a simple 3D volume with 4 channels\n",
        "        image_data = np.zeros((4, 64, 64, 64), dtype=np.float32)\n",
        "\n",
        "        # Fill with sample patterns\n",
        "        for c in range(4):\n",
        "            x, y, z = np.ogrid[:64, :64, :64]\n",
        "            center = 32\n",
        "            radius = 20 - c * 2  # Different radius per channel\n",
        "            sphere = ((x - center)**2 + (y - center)**2 + (z - center)**2) <= radius**2\n",
        "            image_data[c] = sphere.astype(float) * (0.8 - c * 0.1) + np.random.rand(64, 64, 64) * 0.2\n",
        "\n",
        "        # Create sample label\n",
        "        label_data = np.zeros((64, 64, 64), dtype=np.uint8)\n",
        "        core_radius = 10\n",
        "        enhancing_radius = 15\n",
        "\n",
        "        core_sphere = ((x - center)**2 + (y - center)**2 + (z - center)**2) <= core_radius**2\n",
        "        enhancing_sphere = ((x - center)**2 + (y - center)**2 + (z - center)**2) <= enhancing_radius**2\n",
        "\n",
        "        label_data[core_sphere] = 1  # Tumor core\n",
        "        label_data[enhancing_sphere & ~core_sphere] = 2  # Enhancing tumor\n",
        "\n",
        "        # Visualize a central slice\n",
        "        central_slice_idx = 32\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        modalities = [\"T1\", \"T1ce\", \"T2\", \"FLAIR\"]\n",
        "        for i in range(4):\n",
        "            plt.subplot(1, 4, i+1)\n",
        "            plt.imshow(image_data[i, :, :, central_slice_idx], cmap=\"gray\")\n",
        "            plt.title(f\"Modality: {modalities[i]}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Sample data visualized successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to visualize sample data: {e}\")"
      ],
      "metadata": {
        "id": "XH5Xb40LmrF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Segmentation Masks\n",
        "# ===================================\n",
        "\n",
        "# Visualize the segmentation masks\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Original image (T1ce modality, which typically shows tumor best)\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image_data[1, :, :, central_slice_idx], cmap=\"gray\")\n",
        "plt.title(\"T1ce MRI\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Segmentation mask\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(label_data[:, :, central_slice_idx], cmap=\"viridis\")\n",
        "plt.title(\"Segmentation Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Overlay segmentation on the image\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(image_data[1, :, :, central_slice_idx], cmap=\"gray\")\n",
        "plt.imshow(label_data[:, :, central_slice_idx], cmap=\"hot\", alpha=0.3)\n",
        "plt.title(\"Overlay\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize tumor regions across multiple slices\n",
        "num_slices = 5\n",
        "start_slice = central_slice_idx - (num_slices // 2)\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "for i in range(num_slices):\n",
        "    slice_idx = start_slice + i\n",
        "    plt.subplot(2, num_slices, i + 1)\n",
        "    plt.imshow(image_data[1, :, :, slice_idx], cmap=\"gray\")\n",
        "    plt.title(f\"Slice {slice_idx}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(2, num_slices, i + 1 + num_slices)\n",
        "    plt.imshow(image_data[1, :, :, slice_idx], cmap=\"gray\")\n",
        "    plt.imshow(label_data[:, :, slice_idx], cmap=\"hot\", alpha=0.3)\n",
        "    plt.title(f\"Overlay {slice_idx}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Count the number of voxels for each label\n",
        "label_counts = {int(label): np.sum(label_data == label) for label in np.unique(label_data)}\n",
        "print(\"\\nVoxel count for each label:\")\n",
        "total_voxels = np.prod(label_data.shape)\n",
        "for label, count in label_counts.items():\n",
        "    percentage = (count / total_voxels) * 100\n",
        "    if label == 0:\n",
        "        class_name = \"Background\"\n",
        "    elif label == 1:\n",
        "        class_name = \"Tumor Core\"\n",
        "    elif label == 2:\n",
        "        class_name = \"Enhancing Tumor\"\n",
        "    else:\n",
        "        class_name = f\"Label {label}\"\n",
        "    print(f\"- {class_name}: {count} voxels ({percentage:.2f}%)\")"
      ],
      "metadata": {
        "id": "G0r840Hqnc6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing and Transforms\n",
        "# =================================\n",
        "\n",
        "# Create training data dictionary of image/label pairs\n",
        "train_images = sorted(os.listdir(os.path.join(data_dir, \"imagesTr\")))\n",
        "train_labels = sorted(os.listdir(os.path.join(data_dir, \"labelsTr\")))\n",
        "\n",
        "train_files = [\n",
        "    {\n",
        "        \"image\": os.path.join(data_dir, \"imagesTr\", img),\n",
        "        \"label\": os.path.join(data_dir, \"labelsTr\", lbl)\n",
        "    }\n",
        "    for img, lbl in zip(train_images, train_labels)\n",
        "]\n",
        "\n",
        "# Split into training and validation sets (80/20 split)\n",
        "val_split = 0.2\n",
        "val_size = int(len(train_files) * val_split)\n",
        "train_files, val_files = train_files[val_size:], train_files[:val_size]\n",
        "\n",
        "print(f\"Number of training samples: {len(train_files)}\")\n",
        "print(f\"Number of validation samples: {len(val_files)}\")\n",
        "\n",
        "# Define preprocessing transforms for training\n",
        "train_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "    ScaleIntensityd(keys=[\"image\"]),\n",
        "    NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "    RandCropByPosNegLabeld(\n",
        "        keys=[\"image\", \"label\"],\n",
        "        label_key=\"label\",\n",
        "        spatial_size=(96, 96, 64),  # Reduced size for Colab memory constraints\n",
        "        pos=1,\n",
        "        neg=1,\n",
        "        num_samples=4,\n",
        "        image_key=\"image\"\n",
        "    ),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "    ToTensord(keys=[\"image\", \"label\"])\n",
        "])\n",
        "\n",
        "# Define preprocessing transforms for validation (no augmentation)\n",
        "val_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "    ScaleIntensityd(keys=[\"image\"]),\n",
        "    NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "    ToTensord(keys=[\"image\", \"label\"])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_ds = CacheDataset(\n",
        "    data=train_files,\n",
        "    transform=train_transforms,\n",
        "    cache_rate=1.0,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "val_ds = CacheDataset(\n",
        "    data=val_files,\n",
        "    transform=val_transforms,\n",
        "    cache_rate=1.0,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=2,  # Reduced batch size for Colab\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=list_data_collate,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=1,\n",
        "    num_workers=2,\n",
        "    collate_fn=list_data_collate,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "# Verify the data shape after transforms\n",
        "check_data = first(train_loader)\n",
        "image, label = check_data[\"image\"], check_data[\"label\"]\n",
        "print(f\"Image shape after transforms: {image.shape}\")\n",
        "print(f\"Label shape after transforms: {label.shape}\")"
      ],
      "metadata": {
        "id": "PeGxzZ1qpJvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture - Encoder Path\n",
        "# =================================\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A Convolution block with two 3D convolutions, instance normalization and LeakyReLU activations\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.norm1 = nn.InstanceNorm3d(out_channels)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.norm2 = nn.InstanceNorm3d(out_channels)\n",
        "        self.activation = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.norm1(self.conv1(x)))\n",
        "        x = self.activation(self.norm2(self.conv2(x)))\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder block that performs convolution followed by downsampling\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv = ConvBlock(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.conv(x)\n",
        "        pooled = self.pool(features)\n",
        "        return pooled, features  # Return both the downsampled output and the features for skip connection\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder path of the 3D U-Net\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=4, depths=[32, 64, 128, 256]):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoders = nn.ModuleList()\n",
        "\n",
        "        # Initial convolution block\n",
        "        self.initial_conv = ConvBlock(in_channels, depths[0])\n",
        "\n",
        "        # Encoder blocks with increasing feature depth\n",
        "        for i in range(len(depths)-1):\n",
        "            self.encoders.append(EncoderBlock(depths[i], depths[i+1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial features\n",
        "        features = [self.initial_conv(x)]\n",
        "\n",
        "        # Encoder path\n",
        "        out = features[0]\n",
        "        for encoder in self.encoders:\n",
        "            out, feature_map = encoder(out)\n",
        "            features.append(feature_map)\n",
        "\n",
        "        return out, features\n",
        "\n",
        "# Test the encoder with a sample input\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a random input tensor (batch_size=2, channels=4, depth=64, height=96, width=96)\n",
        "    x = torch.randn(2, 4, 64, 96, 96).to(device)\n",
        "\n",
        "    # Initialize the encoder\n",
        "    encoder = Encoder(in_channels=4, depths=[32, 64, 128, 256]).to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    out, features = encoder(x)\n",
        "\n",
        "    print(\"Encoder output shape:\", out.shape)\n",
        "    print(\"Feature maps shapes:\")\n",
        "    for i, feature in enumerate(features):\n",
        "        print(f\"  Level {i}: {feature.shape}\")"
      ],
      "metadata": {
        "id": "kRF-BHbwpSzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture - Decoder Path\n",
        "# =================================\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder block that performs upsampling followed by convolution\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, skip_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.upconv = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv = ConvBlock(in_channels // 2 + skip_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip_features):\n",
        "        # Upsample\n",
        "        x = self.upconv(x)\n",
        "\n",
        "        # Handle potential size mismatch for skip connection\n",
        "        if x.shape[2:] != skip_features.shape[2:]:\n",
        "            x = F.interpolate(x, size=skip_features.shape[2:], mode='trilinear', align_corners=False)\n",
        "\n",
        "        # Concatenate with skip features\n",
        "        x = torch.cat([x, skip_features], dim=1)\n",
        "\n",
        "        # Apply convolution\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder path of the 3D U-Net\n",
        "    \"\"\"\n",
        "    def __init__(self, depths=[256, 128, 64, 32]):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoders = nn.ModuleList()\n",
        "\n",
        "        # Create decoder blocks with decreasing feature depth\n",
        "        for i in range(len(depths)-1):\n",
        "            self.decoders.append(DecoderBlock(depths[i], depths[i+1], depths[i+1]))\n",
        "\n",
        "    def forward(self, x, encoder_features):\n",
        "        # Decoder path\n",
        "        out = x\n",
        "\n",
        "        # Use encoder features in reverse order (excluding bottleneck)\n",
        "        skip_features = encoder_features[-2::-1]\n",
        "\n",
        "        for i, decoder in enumerate(self.decoders):\n",
        "            out = decoder(out, skip_features[i])\n",
        "\n",
        "        return out\n",
        "\n",
        "# Test the decoder with a sample input and features from encoder\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a random input tensor (batch_size=2, channels=256, depth=8, height=12, width=12)\n",
        "    x = torch.randn(2, 256, 8, 12, 12).to(device)\n",
        "\n",
        "    # Create sample encoder features\n",
        "    encoder_features = [\n",
        "        torch.randn(2, 32, 64, 96, 96).to(device),  # Level 0\n",
        "        torch.randn(2, 64, 32, 48, 48).to(device),  # Level 1\n",
        "        torch.randn(2, 128, 16, 24, 24).to(device), # Level 2\n",
        "        torch.randn(2, 256, 8, 12, 12).to(device)   # Level 3 (bottleneck)\n",
        "    ]\n",
        "\n",
        "    # Initialize the decoder\n",
        "    decoder = Decoder(depths=[256, 128, 64, 32]).to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    out = decoder(x, encoder_features)\n",
        "\n",
        "    print(\"Decoder output shape:\", out.shape)"
      ],
      "metadata": {
        "id": "kO209nKZpUsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture - Full 3D U-Net\n",
        "# ==================================\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete 3D U-Net model for volumetric segmentation\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=4, out_channels=3, feature_channels=[32, 64, 128, 256]):\n",
        "        super(UNet3D, self).__init__()\n",
        "\n",
        "        # Encoder and decoder paths\n",
        "        self.encoder = Encoder(in_channels, feature_channels)\n",
        "        self.bottleneck = ConvBlock(feature_channels[-1], feature_channels[-1]*2)\n",
        "        self.decoder = Decoder([feature_channels[-1]*2] + feature_channels[::-1][:-1])\n",
        "\n",
        "        # Final convolution to produce segmentation map\n",
        "        self.final_conv = nn.Conv3d(feature_channels[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        enc_out, features = self.encoder(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(enc_out)\n",
        "\n",
        "        # Decoder path\n",
        "        dec_out = self.decoder(bottleneck, features)\n",
        "\n",
        "        # Final convolution\n",
        "        logits = self.final_conv(dec_out)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        \"\"\"Initialize model weights\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv3d, nn.ConvTranspose3d)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.InstanceNorm3d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Create the model and move to device\n",
        "model = UNet3D(in_channels=4, out_channels=3).to(device)\n",
        "model.initialize_weights()\n",
        "\n",
        "# Print model summary\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total trainable parameters: {total_params:,}\")\n",
        "\n",
        "# Test with a sample input\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a random input tensor (batch_size=2, channels=4, depth=64, height=96, width=96)\n",
        "    x = torch.randn(2, 4, 64, 96, 96).to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "    # Check if output matches expected dimensions\n",
        "    print(\"Output channels (should be 3 for background, tumor core, enhancing tumor):\", output.shape[1])\n",
        "    print(\"Output spatial dimensions match input:\", output.shape[2:] == x.shape[2:])"
      ],
      "metadata": {
        "id": "lTNojAbPpVht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function and Evaluation Metrics\n",
        "# ===================================\n",
        "\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "from monai.metrics import DiceMetric, HausdorffDistanceMetric, ConfusionMatrixMetric\n",
        "\n",
        "# Define the loss function\n",
        "# DiceCELoss combines Dice loss and Cross-Entropy loss\n",
        "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
        "\n",
        "# Define evaluation metrics\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "hausdorff_metric = HausdorffDistanceMetric(include_background=False, reduction=\"mean\", percentile=95)\n",
        "confusion_matrix = ConfusionMatrixMetric(include_background=False,\n",
        "                                         metric_name=[\"sensitivity\", \"specificity\", \"precision\"],\n",
        "                                         compute_sample=True)\n",
        "\n",
        "def calculate_metrics(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    Calculate and return multiple evaluation metrics\n",
        "    \"\"\"\n",
        "    # Convert predictions to one-hot format\n",
        "    y_pred = torch.argmax(y_pred, dim=1, keepdim=True)\n",
        "\n",
        "    # Compute Dice score\n",
        "    dice_score = dice_metric(y_pred, y_true)\n",
        "\n",
        "    # Compute Hausdorff distance\n",
        "    hausdorff_score = hausdorff_metric(y_pred, y_true)\n",
        "\n",
        "    # Compute sensitivity, specificity, and precision\n",
        "    confusion_matrix(y_pred, y_true)\n",
        "    metrics = confusion_matrix.aggregate()[0]\n",
        "    sensitivity = metrics[0].item()\n",
        "    specificity = metrics[1].item()\n",
        "    precision = metrics[2].item()\n",
        "\n",
        "    return {\n",
        "        \"dice\": dice_score.item(),\n",
        "        \"hausdorff\": hausdorff_score.item(),\n",
        "        \"sensitivity\": sensitivity,\n",
        "        \"specificity\": specificity,\n",
        "        \"precision\": precision\n",
        "    }\n",
        "\n",
        "# Reset metrics\n",
        "def reset_metrics():\n",
        "    dice_metric.reset()\n",
        "    hausdorff_metric.reset()\n",
        "    confusion_matrix.reset()\n",
        "\n",
        "# Test the loss function with random inputs\n",
        "if __name__ == \"__main__\":\n",
        "    # Create random predictions and targets\n",
        "    y_pred = torch.randn(2, 3, 64, 96, 96).to(device)  # [batch, channels, d, h, w]\n",
        "    y_true = torch.randint(0, 3, (2, 1, 64, 96, 96)).to(device)  # [batch, channels, d, h, w]\n",
        "\n",
        "    # Calculate loss\n",
        "    loss_val = loss_function(y_pred, y_true)\n",
        "    print(f\"Loss value: {loss_val.item()}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_metrics(y_pred, y_true)\n",
        "    print(\"Metrics:\")\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        print(f\"  {metric_name}: {metric_value}\")"
      ],
      "metadata": {
        "id": "cRVN0z97pXU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Setup\n",
        "# =============\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "# Reduce learning rate when validation loss plateaus\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        ")\n",
        "\n",
        "# Number of epochs\n",
        "max_epochs = 50  # Adjust based on available time\n",
        "early_stop_patience = 10  # Stop training if validation loss doesn't improve for this many epochs\n",
        "\n",
        "# Initialize variables to track best model\n",
        "best_val_loss = float('inf')\n",
        "best_val_dice = 0.0\n",
        "best_epoch = 0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "# Save best model\n",
        "model_save_path = \"best_model.pth\"\n",
        "\n",
        "# Create dictionaries to store metrics\n",
        "train_metrics = {\n",
        "    'loss': [],\n",
        "    'dice': []\n",
        "}\n",
        "\n",
        "val_metrics = {\n",
        "    'loss': [],\n",
        "    'dice': [],\n",
        "    'hausdorff': [],\n",
        "    'sensitivity': [],\n",
        "    'specificity': [],\n",
        "    'precision': []\n",
        "}\n",
        "\n",
        "# Use mixed precision training to speed up and reduce memory usage\n",
        "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "# Display training configuration\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"- Device: {device}\")\n",
        "print(f\"- Max Epochs: {max_epochs}\")\n",
        "print(f\"- Batch Size: {train_loader.batch_size}\")\n",
        "print(f\"- Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "print(f\"- Early Stop Patience: {early_stop_patience}\")\n",
        "print(f\"- Training Samples: {len(train_ds)}\")\n",
        "print(f\"- Validation Samples: {len(val_ds)}\")\n",
        "print(f\"- Mixed Precision: {'Enabled' if scaler else 'Disabled'}\")"
      ],
      "metadata": {
        "id": "wZuXJeGTpb8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "# ============\n",
        "\n",
        "def train_epoch(model, loader, optimizer, loss_function, scaler=None):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
        "\n",
        "    for step, batch in progress_bar:\n",
        "        # Get data and move to device\n",
        "        inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_function(outputs, labels)\n",
        "\n",
        "            # Backward and optimize with gradient scaling\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            # Standard forward/backward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({'batch_loss': loss.item()})\n",
        "\n",
        "    # Calculate average loss\n",
        "    epoch_loss /= (step + 1)\n",
        "\n",
        "    # Calculate Dice score on training set\n",
        "    pred = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "    dice_score = dice_metric(pred, labels)\n",
        "    dice_metric.reset()\n",
        "\n",
        "    return epoch_loss, dice_score.item()\n",
        "\n",
        "# Example usage if running as main script\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Training function defined and ready to use in the training loop.\")"
      ],
      "metadata": {
        "id": "3XXtxYdtpdts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Loop\n",
        "# ==============\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, loss_function):\n",
        "    \"\"\"\n",
        "    Validate the model on the validation set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    step = 0\n",
        "\n",
        "    # Reset metrics\n",
        "    reset_metrics()\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Validation\")\n",
        "\n",
        "    for step, batch in progress_bar:\n",
        "        # Get data and move to device\n",
        "        inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "\n",
        "        # Use sliding window inference for larger volumes\n",
        "        roi_size = (96, 96, 64)\n",
        "        sw_batch_size = 4\n",
        "\n",
        "        outputs = sliding_window_inference(inputs, roi_size, sw_batch_size, model)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Update loss\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        pred = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "        dice_metric(pred, labels)\n",
        "        hausdorff_metric(pred, labels)\n",
        "        confusion_matrix(pred, labels)\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({'batch_loss': loss.item()})\n",
        "\n",
        "    # Calculate average loss\n",
        "    val_loss /= (step + 1)\n",
        "\n",
        "    # Aggregate metrics\n",
        "    dice_score = dice_metric.aggregate().item()\n",
        "    hausdorff_score = hausdorff_metric.aggregate().item()\n",
        "\n",
        "    confusion_values = confusion_matrix.aggregate()[0]\n",
        "    sensitivity = confusion_values[0].item()\n",
        "    specificity = confusion_values[1].item()\n",
        "    precision = confusion_values[2].item()\n",
        "\n",
        "    # Reset metrics for next validation\n",
        "    reset_metrics()\n",
        "\n",
        "    metrics = {\n",
        "        'loss': val_loss,\n",
        "        'dice': dice_score,\n",
        "        'hausdorff': hausdorff_score,\n",
        "        'sensitivity': sensitivity,\n",
        "        'specificity': specificity,\n",
        "        'precision': precision\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Example usage if running as main script\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Validation function defined and ready to use in the training loop.\")"
      ],
      "metadata": {
        "id": "LRKoPJqppfL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training Execution\n",
        "# =======================\n",
        "\n",
        "# Let's train the model\n",
        "def train_model(model, train_loader, val_loader, optimizer, loss_function, max_epochs, scheduler=None, scaler=None):\n",
        "    \"\"\"\n",
        "    Train the model for multiple epochs\n",
        "    \"\"\"\n",
        "    # Initialize tracking variables\n",
        "    best_val_dice = 0\n",
        "    best_epoch = 0\n",
        "    epochs_without_improvement = 0\n",
        "    model_save_path = \"best_model.pth\"\n",
        "\n",
        "    # Track metrics\n",
        "    train_loss_values = []\n",
        "    train_dice_values = []\n",
        "    val_loss_values = []\n",
        "    val_dice_values = []\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{max_epochs}\")\n",
        "\n",
        "        # Train for one epoch\n",
        "        train_loss, train_dice = train_epoch(model, train_loader, optimizer, loss_function, scaler)\n",
        "\n",
        "        # Validate the model\n",
        "        val_metrics = validate(model, val_loader, loss_function)\n",
        "        val_loss = val_metrics['loss']\n",
        "        val_dice = val_metrics['dice']\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
        "        print(f\"Val Hausdorff: {val_metrics['hausdorff']:.4f}\")\n",
        "        print(f\"Val Sensitivity: {val_metrics['sensitivity']:.4f}, Val Specificity: {val_metrics['specificity']:.4f}, Val Precision: {val_metrics['precision']:.4f}\")\n",
        "\n",
        "        # Track metrics\n",
        "        train_loss_values.append(train_loss)\n",
        "        train_dice_values.append(train_dice)\n",
        "        val_loss_values.append(val_loss)\n",
        "        val_dice_values.append(val_dice)\n",
        "\n",
        "        # Update learning rate scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_dice > best_val_dice:\n",
        "            best_val_dice = val_dice\n",
        "            best_epoch = epoch\n",
        "            epochs_without_improvement = 0\n",
        "\n",
        "            # Save model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_dice': val_dice,\n",
        "                'val_metrics': val_metrics\n",
        "            }, model_save_path)\n",
        "\n",
        "            print(f\"Best model saved at epoch {epoch+1} with validation Dice score: {val_dice:.4f}\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            print(f\"No improvement for {epochs_without_improvement} epochs (best Dice: {best_val_dice:.4f} at epoch {best_epoch+1})\")\n",
        "\n",
        "        # Early stopping\n",
        "        if epochs_without_improvement >= early_stop_patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    # Plot training curves\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_loss_values, label='Train Loss')\n",
        "    plt.plot(val_loss_values, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss Curves')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_dice_values, label='Train Dice')\n",
        "    plt.plot(val_dice_values, label='Val Dice')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Dice Score')\n",
        "    plt.legend()\n",
        "    plt.title('Dice Score Curves')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return model_save_path, best_epoch, best_val_dice\n",
        "\n",
        "# Start training with a smaller number of epochs for Colab demo\n",
        "num_epochs = 5  # Reduced for demonstration\n",
        "print(f\"Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "# Train the model\n",
        "best_model_path, best_epoch, best_dice = train_model(\n",
        "    model, train_loader, val_loader, optimizer, loss_function,\n",
        "    max_epochs=num_epochs, scheduler=scheduler, scaler=scaler\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Best model saved at {best_model_path}\")\n",
        "print(f\"Best validation Dice score: {best_dice:.4f} at epoch {best_epoch+1}\")"
      ],
      "metadata": {
        "id": "vCm33gSUpf50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Inference\n",
        "# ==============\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer(model, image):\n",
        "    \"\"\"\n",
        "    Run inference on a single image\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Use sliding window inference for large volumes\n",
        "    roi_size = (96, 96, 64)\n",
        "    sw_batch_size = 4\n",
        "\n",
        "    # Perform inference\n",
        "    output = sliding_window_inference(image, roi_size, sw_batch_size, model)\n",
        "\n",
        "    # Get prediction\n",
        "    pred = torch.argmax(output, dim=1, keepdim=True)\n",
        "\n",
        "    return pred\n",
        "\n",
        "# Load the best model\n",
        "def load_best_model(model, model_path):\n",
        "    \"\"\"\n",
        "    Load the best model from checkpoint\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    best_val_dice = checkpoint['val_dice']\n",
        "\n",
        "    print(f\"Loaded best model from epoch {best_epoch+1} with validation Dice score: {best_val_dice:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load the best model\n",
        "model = load_best_model(model, best_model_path)\n",
        "\n",
        "# Get a batch from the validation dataset\n",
        "val_data = first(val_loader)\n",
        "val_image = val_data[\"image\"].to(device)\n",
        "val_label = val_data[\"label\"].to(device)\n",
        "\n",
        "# Run inference\n",
        "pred = infer(model, val_image)\n",
        "\n",
        "# Print shapes\n",
        "print(f\"Image shape: {val_image.shape}\")\n",
        "print(f\"Label shape: {val_label.shape}\")\n",
        "print(f\"Prediction shape: {pred.shape}\")\n",
        "\n",
        "# Calculate metrics\n",
        "metrics = calculate_metrics(torch.argmax(model(val_image), dim=1, keepdim=True), val_label)\n",
        "print(\"\\nInference Metrics:\")\n",
        "for metric_name, metric_value in metrics.items():\n",
        "    print(f\"  {metric_name}: {metric_value:.4f}\")"
      ],
      "metadata": {
        "id": "7gzMXeGwpiCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results Visualization\n",
        "# ====================\n",
        "\n",
        "def visualize_results(image, label, pred, slice_idx=None, modality_idx=1):\n",
        "    \"\"\"\n",
        "    Visualize the results of segmentation\n",
        "    \"\"\"\n",
        "    # Get data from tensors\n",
        "    image_np = image.detach().cpu().numpy()\n",
        "    label_np = label.detach().cpu().numpy()\n",
        "    pred_np = pred.detach().cpu().numpy()\n",
        "\n",
        "    # Get dimensions\n",
        "    _, C, D, H, W = image_np.shape\n",
        "\n",
        "    # If slice_idx is not provided, use the middle slice\n",
        "    if slice_idx is None:\n",
        "        slice_idx = D // 2\n",
        "\n",
        "    # Get the selected modality (T1ce is usually the most informative, index 1)\n",
        "    image_slice = image_np[0, modality_idx, slice_idx, :, :]\n",
        "    label_slice = label_np[0, 0, slice_idx, :, :]\n",
        "    pred_slice = pred_np[0, 0, slice_idx, :, :]\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Display the original image\n",
        "    axes[0].imshow(image_slice, cmap='gray')\n",
        "    axes[0].set_title(f'Original MRI (Modality {modality_idx})')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Display the ground truth segmentation mask\n",
        "    axes[1].imshow(image_slice, cmap='gray')\n",
        "    mask = np.ma.masked_where(label_slice == 0, label_slice)\n",
        "    axes[1].imshow(mask, cmap='hot', alpha=0.7)\n",
        "    axes[1].set_title('Ground Truth Segmentation')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Display the predicted segmentation mask\n",
        "    axes[2].imshow(image_slice, cmap='gray')\n",
        "    mask = np.ma.masked_where(pred_slice == 0, pred_slice)\n",
        "    axes[2].imshow(mask, cmap='hot', alpha=0.7)\n",
        "    axes[2].set_title('Predicted Segmentation')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize results across multiple slices\n",
        "def visualize_multiple_slices(image, label, pred, num_slices=5, modality_idx=1):\n",
        "    \"\"\"\n",
        "    Visualize results across multiple slices\n",
        "    \"\"\"\n",
        "    # Get data from tensors\n",
        "    image_np = image.detach().cpu().numpy()\n",
        "    label_np = label.detach().cpu().numpy()\n",
        "    pred_np = pred.detach().cpu().numpy()\n",
        "\n",
        "    # Get dimensions\n",
        "    _, C, D, H, W = image_np.shape\n",
        "\n",
        "    # Calculate slice indices\n",
        "    slice_indices = np.linspace(D // 4, 3 * D // 4, num_slices, dtype=int)\n",
        "\n",
        "    # Create a large figure\n",
        "    fig, axes = plt.subplots(3, num_slices, figsize=(20, 10))\n",
        "\n",
        "    # For each slice\n",
        "    for i, slice_idx in enumerate(slice_indices):\n",
        "        # Get the selected modality slice\n",
        "        image_slice = image_np[0, modality_idx, slice_idx, :, :]\n",
        "        label_slice = label_np[0, 0, slice_idx, :, :]\n",
        "        pred_slice = pred_np[0, 0, slice_idx, :, :]\n",
        "\n",
        "        # Display the original image\n",
        "        axes[0, i].imshow(image_slice, cmap='gray')\n",
        "        if i == 0:\n",
        "            axes[0, i].set_ylabel('Original MRI')\n",
        "        axes[0, i].set_title(f'Slice {slice_idx}')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # Display the ground truth segmentation\n",
        "        axes[1, i].imshow(image_slice, cmap='gray')\n",
        "        mask = np.ma.masked_where(label_slice == 0, label_slice)\n",
        "        axes[1, i].imshow(mask, cmap='hot', alpha=0.7)\n",
        "        if i == 0:\n",
        "            axes[1, i].set_ylabel('Ground Truth')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "        # Display the predicted segmentation\n",
        "        axes[2, i].imshow(image_slice, cmap='gray')\n",
        "        mask = np.ma.masked_where(pred_slice == 0, pred_slice)\n",
        "        axes[2, i].imshow(mask, cmap='hot', alpha=0.7)\n",
        "        if i == 0:\n",
        "            axes[2, i].set_ylabel('Prediction')\n",
        "        axes[2, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a single slice\n",
        "print(\"Visualization of a single slice:\")\n",
        "visualize_results(val_image, val_label, pred)\n",
        "\n",
        "# Visualize multiple slices\n",
        "print(\"\\nVisualization across multiple slices:\")\n",
        "visualize_multiple_slices(val_image, val_label, pred, num_slices=5)"
      ],
      "metadata": {
        "id": "jIx2JWvupkBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation and Conclusion\n",
        "# =========================\n",
        "\n",
        "# Calculate Dice score per class\n",
        "def calculate_class_wise_dice(pred, target, num_classes=3):\n",
        "    \"\"\"\n",
        "    Calculate Dice score for each class separately\n",
        "    \"\"\"\n",
        "    dice_scores = []\n",
        "\n",
        "    # Convert tensors to numpy arrays\n",
        "    pred = pred.detach().cpu().numpy().squeeze()\n",
        "    target = target.detach().cpu().numpy().squeeze()\n",
        "\n",
        "    for i in range(1, num_classes):  # Skip background class (0)\n",
        "        # Binary masks for this class\n",
        "        class_pred = (pred == i).astype(np.float32)\n",
        "        class_target = (target == i).astype(np.float32)\n",
        "\n",
        "        # Calculate intersection and union\n",
        "        intersection = np.sum(class_pred * class_target)\n",
        "        union = np.sum(class_pred) + np.sum(class_target)\n",
        "\n",
        "        # Calculate Dice score\n",
        "        dice = (2.0 * intersection) / (union + 1e-5)\n",
        "        dice_scores.append(dice)\n",
        "\n",
        "    return dice_scores\n",
        "\n",
        "# Calculate class-wise Dice scores\n",
        "class_wise_dice = calculate_class_wise_dice(pred, val_label)\n",
        "class_names = [\"Tumor Core\", \"Enhancing Tumor\"]\n",
        "\n",
        "print(\"\\nClass-wise Dice Scores:\")\n",
        "for i, (class_name, dice) in enumerate(zip(class_names, class_wise_dice)):\n",
        "    print(f\"  {class_name}: {dice:.4f}\")\n",
        "\n",
        "# Create a summary of the model and results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BrainSeg3D: 3D U-Net for Brain Tumor Segmentation\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nModel Architecture:\")\n",
        "print(f\"- Input Channels: 4 (T1, T1ce, T2, FLAIR MRI modalities)\")\n",
        "print(f\"- Output Channels: 3 (Background, Tumor Core, Enhancing Tumor)\")\n",
        "print(f\"- Architecture: 3D U-Net with skip connections\")\n",
        "print(f\"- Total Parameters: {count_parameters(model):,}\")\n",
        "\n",
        "print(\"\\nTraining Summary:\")\n",
        "print(f\"- Training Samples: {len(train_ds)}\")\n",
        "print(f\"- Validation Samples: {len(val_ds)}\")\n",
        "print(f\"- Best Validation Dice Score: {best_dice:.4f} (Epoch {best_epoch+1})\")\n",
        "\n",
        "print(\"\\nFinal Evaluation Metrics:\")\n",
        "for metric_name, metric_value in metrics.items():\n",
        "    print(f\"  {metric_name}: {metric_value:.4f}\")\n",
        "\n",
        "print(\"\\nClass-wise Dice Scores:\")\n",
        "for i, (class_name, dice) in enumerate(zip(class_names, class_wise_dice)):\n",
        "    print(f\"  {class_name}: {dice:.4f}\")\n",
        "\n",
        "print(\"\\nConclusion:\")\n",
        "print(\"We have successfully implemented a 3D U-Net model for brain tumor segmentation\")\n",
        "print(\"using multi-modal MRI data. The model demonstrates the application of deep\")\n",
        "print(\"learning for medical image segmentation, particularly in neuroimaging.\")\n",
        "\n",
        "print(\"\\nPotential Improvements:\")\n",
        "print(\"1. Train with more data for better generalization\")\n",
        "print(\"2. Experiment with different architectures (e.g., Attention U-Net)\")\n",
        "print(\"3. Use more advanced data augmentation techniques\")\n",
        "print(\"4. Implement post-processing to refine segmentation boundaries\")\n",
        "print(\"5. Explore different loss functions (e.g., Focal Dice Loss)\")"
      ],
      "metadata": {
        "id": "5DnevD2qpm84"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}